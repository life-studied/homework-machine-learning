# 05 一对多分类

​	一对多分类是在二分类的基础上进行拓展的。

​	如果有$k$种分类，做法是：训练出$k$个$h(x)$，第$i$个$h(x)^{(i)}$代表输入$x$为第$i$种分类的概率。算出所有$h(x)$，选择最大的概率，则该样本为对应的分类。

## 步骤

* 输入数据集，将其复制$k$份，每份数据集都指定一个分类值为1，其余分类值为0
* 将$k$份数据集输入到二分类模型中，获取$k$份$h(x)$
* 对输入的新样本$x_{n+1}$进行$h(x)$计算，选出$max$作为实际类别。

## 正则化优化过拟合问题

​	对于高阶函数，可能出现假设函数h(x)为了拟合数据而失去了泛化的能力（即只保证肯定能经过测试点数据，但是失去了对新数据的泛化能力）。对于这个问题，正则化是一个较好的解决方案。

​	正则化是指，在代价函数中加上$\lambda_i\theta_i^2$项，使其惩罚这几个参数，让其在原假设函数中的比重减少，更多的比重加在其它$\theta$参数项上，从而使其变为一个更平滑的高阶函数。

​	对每一个$\theta$项进行上述处理，就可以自动调整每个$\theta$的比重来使得最终结果更平滑，从而防止过拟合。

​	即$J(\theta) = \frac{1}{2m} \sum_{i = 1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2 - \sum_{i = 1}^{m}\lambda_i\theta_i^2$。

---

​	采取正则化处理中，不能将$\lambda_i$设置的过大（对$\theta_i$惩罚的过大），否则相当于在$h(x)$中忽略所有的$x_i$项，最终只有$\theta_0$（即一条横着的直线），导致欠拟合。